{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def optimize_dataframe(df):\n",
    "    optimized_df = pd.DataFrame()\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_data = df[col]\n",
    "        dtype = col_data.dtype\n",
    "\n",
    "        if dtype == object:\n",
    "            # If dtype is object, convert to category if less than 50% unique\n",
    "            num_unique_values = len(col_data.unique())\n",
    "            num_total_values = len(col_data)\n",
    "            if num_unique_values / num_total_values < 0.5:\n",
    "                optimized_df[col] = col_data.astype('category')\n",
    "            else:\n",
    "                optimized_df[col] = col_data\n",
    "        elif dtype == int:\n",
    "            # If dtype is int, check if it can be converted to smaller int dtype\n",
    "            if col_data.min() >= 0:\n",
    "                if col_data.max() < 2**8:\n",
    "                    optimized_df[col] = col_data.astype('uint8')\n",
    "                elif col_data.max() < 2**16:\n",
    "                    optimized_df[col] = col_data.astype('uint16')\n",
    "                elif col_data.max() < 2**32:\n",
    "                    optimized_df[col] = col_data.astype('uint32')\n",
    "                else:\n",
    "                    optimized_df[col] = col_data.astype('uint64')\n",
    "            else:\n",
    "                if col_data.min() > np.iinfo(np.int8).min and col_data.max() < np.iinfo(np.int8).max:\n",
    "                    optimized_df[col] = col_data.astype('int8')\n",
    "                elif col_data.min() > np.iinfo(np.int16).min and col_data.max() < np.iinfo(np.int16).max:\n",
    "                    optimized_df[col] = col_data.astype('int16')\n",
    "                elif col_data.min() > np.iinfo(np.int32).min and col_data.max() < np.iinfo(np.int32).max:\n",
    "                    optimized_df[col] = col_data.astype('int32')\n",
    "                else:\n",
    "                    optimized_df[col] = col_data.astype('int64')\n",
    "        elif dtype == float:\n",
    "            # If dtype is float, check if it can be converted to smaller float dtype\n",
    "            if col_data.min() > np.finfo(np.float16).min and col_data.max() < np.finfo(np.float16).max:\n",
    "                optimized_df[col] = col_data.astype('float16')\n",
    "            elif col_data.min() > np.finfo(np.float32).min and col_data.max() < np.finfo(np.float32).max:\n",
    "                optimized_df[col] = col_data.astype('float32')\n",
    "            else:\n",
    "                optimized_df[col] = col_data.astype('float64')\n",
    "        else:\n",
    "            optimized_df[col] = col_data\n",
    "\n",
    "    return optimized_df\n",
    "\n",
    "def ffill_numerical(df):\n",
    "    for col in df.columns:\n",
    "        col_data = df[col]\n",
    "        dtype = col_data.dtype\n",
    "    \n",
    "        if np.issubdtype(dtype, np.number):\n",
    "            df[col] = df[col].fillna(method = 'ffill',)\n",
    "    return df\n",
    "\n",
    "def create_lagged_variables(df, var_list, n_lags):\n",
    "    for var in var_list:\n",
    "        for i in range(1, n_lags+1):\n",
    "            col_name = f\"{var}_lag{i}\"\n",
    "            df[col_name] = df[var].shift(i)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet('finals/train.parquet')\n",
    "Val = pd.read_parquet('finals/val.parquet')\n",
    "test = pd.read_parquet('finals/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['month_of_year', 'day_of_year', 'day_of_month', 'week_of_year', 'week_of_month']]= train[['month_of_year', 'day_of_year', 'day_of_month', 'week_of_year', 'week_of_month']].astype('category')\n",
    "Val[['month_of_year', 'day_of_year', 'day_of_month', 'week_of_year', 'week_of_month']]= Val[['month_of_year', 'day_of_year', 'day_of_month', 'week_of_year', 'week_of_month']].astype('category')\n",
    "test[['month_of_year', 'day_of_year', 'day_of_month', 'week_of_year', 'week_of_month']]= test[['month_of_year', 'day_of_year', 'day_of_month', 'week_of_year', 'week_of_month']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y_train = (le.fit_transform(train['Signal14']))\n",
    "X_train = train.drop(['Signal14', 'Date'], axis=1)\n",
    "\n",
    "y_val = le.transform(Val['Signal14'])\n",
    "X_val = train.drop(['Signal14', 'Date'], axis=1)\n",
    "\n",
    "y_test = le.transform(test['Signal14'])\n",
    "X_test = train.drop(['Signal14', 'Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class frequencies\n",
    "unique_classes, counts = np.unique(y_train, return_counts=True)\n",
    "class_freqs = dict(zip(unique_classes, counts))\n",
    "\n",
    "# Calculate the inverse of class frequencies\n",
    "class_weights = {cls: 1.0 / freq for cls, freq in class_freqs.items()}\n",
    "\n",
    "# Normalize the weights (optional)\n",
    "total_weight = sum(class_weights.values())\n",
    "class_weights = {cls: weight / total_weight for cls, weight in class_weights.items()}\n",
    "\n",
    "# Compute sample weights for the training set\n",
    "sample_weights = np.array([class_weights[label] for label in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[20:38:58] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/data/data.cc:455: Check failed: this->labels.Size() % this->num_row_ == 0 (1494 vs. 0) : Incorrect size for labels.\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000013f3e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n  [bt] (1) 2   libxgboost.dylib                    0x000000013f4695a4 xgboost::MetaInfo::SetInfoFromHost(xgboost::GenericParameter const&, xgboost::StringView, xgboost::Json) + 732\n  [bt] (2) 3   libxgboost.dylib                    0x000000013f46916c xgboost::MetaInfo::SetInfo(xgboost::GenericParameter const&, xgboost::StringView, xgboost::StringView) + 164\n  [bt] (3) 4   libxgboost.dylib                    0x000000013f3fa800 XGDMatrixSetInfoFromInterface + 224\n  [bt] (4) 5   libffi.8.dylib                      0x000000010131004c ffi_call_SYSV + 76\n  [bt] (5) 6   libffi.8.dylib                      0x000000010130d74c ffi_call_int + 1208\n  [bt] (6) 7   _ctypes.cpython-311-darwin.so       0x00000001012f08bc _ctypes_callproc + 1232\n  [bt] (7) 8   _ctypes.cpython-311-darwin.so       0x00000001012eaa70 PyCFuncPtr_call + 1216\n  [bt] (8) 9   python3.11                          0x000000010093f8c4 _PyObject_MakeTpCall + 332\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m final_model \u001b[39m=\u001b[39m XGBClassifier(objective \u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMulti:softprob\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      3\u001b[0m                       enable_categorical\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \n\u001b[1;32m      4\u001b[0m                       tree_method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhist\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m                       learning_rate \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m,\n\u001b[1;32m     10\u001b[0m                       )\n\u001b[0;32m---> 12\u001b[0m final_model\u001b[39m.\u001b[39;49mfit(X_train, y_train, \n\u001b[1;32m     13\u001b[0m           eval_set\u001b[39m=\u001b[39;49m[(X_train, y_train), (X_val, y_val)],\n\u001b[1;32m     14\u001b[0m           sample_weight\u001b[39m=\u001b[39;49msample_weights,\n\u001b[1;32m     15\u001b[0m           verbose\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m\n\u001b[1;32m     16\u001b[0m           )\n\u001b[1;32m     17\u001b[0m final_model\u001b[39m.\u001b[39msave_model(\u001b[39m'\u001b[39m\u001b[39mfinal model 26-04-23.json\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m result \u001b[39m=\u001b[39m final_model\u001b[39m.\u001b[39mevals_result()\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/sklearn.py:1471\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1460\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mnum_class\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[0;32m-> 1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1474\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   1475\u001b[0m     group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1476\u001b[0m     qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1477\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1478\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1479\u001b[0m     feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m   1480\u001b[0m     eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[1;32m   1481\u001b[0m     sample_weight_eval_set\u001b[39m=\u001b[39;49msample_weight_eval_set,\n\u001b[1;32m   1482\u001b[0m     base_margin_eval_set\u001b[39m=\u001b[39;49mbase_margin_eval_set,\n\u001b[1;32m   1483\u001b[0m     eval_group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1484\u001b[0m     eval_qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1485\u001b[0m     create_dmatrix\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dmatrix,\n\u001b[1;32m   1486\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_categorical,\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[1;32m   1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1491\u001b[0m     params,\n\u001b[1;32m   1492\u001b[0m     train_dmatrix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[1;32m   1502\u001b[0m )\n\u001b[1;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/sklearn.py:499\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[1;32m    497\u001b[0m         evals\u001b[39m.\u001b[39mappend(train_dmatrix)\n\u001b[1;32m    498\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m         m \u001b[39m=\u001b[39m create_dmatrix(\n\u001b[1;32m    500\u001b[0m             data\u001b[39m=\u001b[39;49mvalid_X,\n\u001b[1;32m    501\u001b[0m             label\u001b[39m=\u001b[39;49mvalid_y,\n\u001b[1;32m    502\u001b[0m             weight\u001b[39m=\u001b[39;49msample_weight_eval_set[i],\n\u001b[1;32m    503\u001b[0m             group\u001b[39m=\u001b[39;49meval_group[i],\n\u001b[1;32m    504\u001b[0m             qid\u001b[39m=\u001b[39;49meval_qid[i],\n\u001b[1;32m    505\u001b[0m             base_margin\u001b[39m=\u001b[39;49mbase_margin_eval_set[i],\n\u001b[1;32m    506\u001b[0m             missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[1;32m    507\u001b[0m             enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[1;32m    508\u001b[0m             feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m    509\u001b[0m             ref\u001b[39m=\u001b[39;49mtrain_dmatrix,\n\u001b[1;32m    510\u001b[0m         )\n\u001b[1;32m    511\u001b[0m         evals\u001b[39m.\u001b[39mappend(m)\n\u001b[1;32m    512\u001b[0m nevals \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(evals)\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/sklearn.py:903\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[0;34m(self, ref, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_method \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mhist\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgpu_hist\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    902\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 903\u001b[0m         \u001b[39mreturn\u001b[39;00m QuantileDMatrix(\n\u001b[1;32m    904\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, ref\u001b[39m=\u001b[39;49mref, nthread\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, max_bin\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_bin\n\u001b[1;32m    905\u001b[0m         )\n\u001b[1;32m    906\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[1;32m    907\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/core.py:1386\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[1;32m   1367\u001b[0m         info \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1368\u001b[0m         \u001b[39mfor\u001b[39;00m info \u001b[39min\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1379\u001b[0m         )\n\u001b[1;32m   1380\u001b[0m     ):\n\u001b[1;32m   1381\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1382\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mIf data iterator is used as input, data like label should be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mspecified as batch argument.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m         )\n\u001b[0;32m-> 1386\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init(\n\u001b[1;32m   1387\u001b[0m     data,\n\u001b[1;32m   1388\u001b[0m     ref\u001b[39m=\u001b[39;49mref,\n\u001b[1;32m   1389\u001b[0m     label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m   1390\u001b[0m     weight\u001b[39m=\u001b[39;49mweight,\n\u001b[1;32m   1391\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1392\u001b[0m     group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m   1393\u001b[0m     qid\u001b[39m=\u001b[39;49mqid,\n\u001b[1;32m   1394\u001b[0m     label_lower_bound\u001b[39m=\u001b[39;49mlabel_lower_bound,\n\u001b[1;32m   1395\u001b[0m     label_upper_bound\u001b[39m=\u001b[39;49mlabel_upper_bound,\n\u001b[1;32m   1396\u001b[0m     feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m   1397\u001b[0m     feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[1;32m   1398\u001b[0m     feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m   1399\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[1;32m   1400\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/core.py:1445\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[0;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[1;32m   1433\u001b[0m config \u001b[39m=\u001b[39m make_jcargs(\n\u001b[1;32m   1434\u001b[0m     nthread\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnthread, missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing, max_bin\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_bin\n\u001b[1;32m   1435\u001b[0m )\n\u001b[1;32m   1436\u001b[0m ret \u001b[39m=\u001b[39m _LIB\u001b[39m.\u001b[39mXGQuantileDMatrixCreateFromCallback(\n\u001b[1;32m   1437\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1438\u001b[0m     it\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1443\u001b[0m     ctypes\u001b[39m.\u001b[39mbyref(handle),\n\u001b[1;32m   1444\u001b[0m )\n\u001b[0;32m-> 1445\u001b[0m it\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1446\u001b[0m \u001b[39m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m _check_call(ret)\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/core.py:488\u001b[0m, in \u001b[0;36mDataIter.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    486\u001b[0m exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    487\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 488\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/core.py:469\u001b[0m, in \u001b[0;36mDataIter._handle_exception\u001b[0;34m(self, fn, dft_ret)\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[39mreturn\u001b[39;00m dft_ret\n\u001b[1;32m    468\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 469\u001b[0m     \u001b[39mreturn\u001b[39;00m fn()\n\u001b[1;32m    470\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     \u001b[39m# Defer the exception in order to return 0 and stop the iteration.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m     \u001b[39m# Exception inside a ctype callback function has no effect except\u001b[39;00m\n\u001b[1;32m    473\u001b[0m     \u001b[39m# for printing to stderr (doesn't stop the execution).\u001b[39;00m\n\u001b[1;32m    474\u001b[0m     tb \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/core.py:534\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mset_info(\n\u001b[1;32m    529\u001b[0m         feature_names\u001b[39m=\u001b[39mfeature_names,\n\u001b[1;32m    530\u001b[0m         feature_types\u001b[39m=\u001b[39mfeature_types,\n\u001b[1;32m    531\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    532\u001b[0m     )\n\u001b[1;32m    533\u001b[0m \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_exception(\u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext(input_data), \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/data.py:1185\u001b[0m, in \u001b[0;36mSingleBatchInternalIter.next\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1184\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mit \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1185\u001b[0m input_data(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m   1186\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/core.py:528\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.input_data\u001b[0;34m(data, feature_names, feature_types, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_temporary_data \u001b[39m=\u001b[39m (new, cat_codes)\n\u001b[1;32m    527\u001b[0m dispatch_proxy_set_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproxy, new, cat_codes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_allow_host)\n\u001b[0;32m--> 528\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproxy\u001b[39m.\u001b[39;49mset_info(\n\u001b[1;32m    529\u001b[0m     feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[1;32m    530\u001b[0m     feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m    531\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    532\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/core.py:819\u001b[0m, in \u001b[0;36mDMatrix.set_info\u001b[0;34m(self, label, weight, base_margin, group, qid, label_lower_bound, label_upper_bound, feature_names, feature_types, feature_weights)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m dispatch_meta_backend\n\u001b[1;32m    818\u001b[0m \u001b[39mif\u001b[39;00m label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 819\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_label(label)\n\u001b[1;32m    820\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    821\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_weight(weight)\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/core.py:950\u001b[0m, in \u001b[0;36mDMatrix.set_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Set label of dmatrix\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \n\u001b[1;32m    944\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[39m    The label information to be set into DMatrix\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    949\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m dispatch_meta_backend\n\u001b[0;32m--> 950\u001b[0m dispatch_meta_backend(\u001b[39mself\u001b[39;49m, label, \u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfloat\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/data.py:1127\u001b[0m, in \u001b[0;36mdispatch_meta_backend\u001b[0;34m(matrix, data, name, dtype)\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \u001b[39mif\u001b[39;00m _is_numpy_array(data):\n\u001b[0;32m-> 1127\u001b[0m     _meta_from_numpy(data, name, dtype, handle)\n\u001b[1;32m   1128\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_df(data):\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/data.py:1050\u001b[0m, in \u001b[0;36m_meta_from_numpy\u001b[0;34m(data, field, dtype, handle)\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMasked array is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1049\u001b[0m interface_str \u001b[39m=\u001b[39m _array_interface(data)\n\u001b[0;32m-> 1050\u001b[0m _check_call(_LIB\u001b[39m.\u001b[39;49mXGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "File \u001b[0;32m~/miniconda3/envs/jobb/lib/python3.11/site-packages/xgboost/core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [20:38:58] /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-cpython-38/xgboost/src/data/data.cc:455: Check failed: this->labels.Size() % this->num_row_ == 0 (1494 vs. 0) : Incorrect size for labels.\nStack trace:\n  [bt] (0) 1   libxgboost.dylib                    0x000000013f3e5bc8 dmlc::LogMessageFatal::~LogMessageFatal() + 124\n  [bt] (1) 2   libxgboost.dylib                    0x000000013f4695a4 xgboost::MetaInfo::SetInfoFromHost(xgboost::GenericParameter const&, xgboost::StringView, xgboost::Json) + 732\n  [bt] (2) 3   libxgboost.dylib                    0x000000013f46916c xgboost::MetaInfo::SetInfo(xgboost::GenericParameter const&, xgboost::StringView, xgboost::StringView) + 164\n  [bt] (3) 4   libxgboost.dylib                    0x000000013f3fa800 XGDMatrixSetInfoFromInterface + 224\n  [bt] (4) 5   libffi.8.dylib                      0x000000010131004c ffi_call_SYSV + 76\n  [bt] (5) 6   libffi.8.dylib                      0x000000010130d74c ffi_call_int + 1208\n  [bt] (6) 7   _ctypes.cpython-311-darwin.so       0x00000001012f08bc _ctypes_callproc + 1232\n  [bt] (7) 8   _ctypes.cpython-311-darwin.so       0x00000001012eaa70 PyCFuncPtr_call + 1216\n  [bt] (8) 9   python3.11                          0x000000010093f8c4 _PyObject_MakeTpCall + 332\n\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "final_model = XGBClassifier(objective ='Multi:softprob', \n",
    "                      enable_categorical=True, \n",
    "                      tree_method='hist', \n",
    "                      n_estimators=10000,\n",
    "                      colsample_bytree=0.8, \n",
    "                      early_stopping_rounds=10, \n",
    "                      eval_metric='mlogloss',\n",
    "                      learning_rate = 0.1,\n",
    "                      )\n",
    "\n",
    "final_model.fit(X_train, y_train, \n",
    "          eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "          sample_weight=sample_weights,\n",
    "          verbose=10\n",
    "          )\n",
    "final_model.save_model('final model 26-04-23.json')\n",
    "\n",
    "result = final_model.evals_result()\n",
    "# plt.figure(figsize=(10,7))\n",
    "plt.style.use(\"default\")\n",
    "plt.plot(result['validation_0']['mlogloss'], label='Training loss')\n",
    "plt.plot(result['validation_1']['mlogloss'], label='Validation loss')\n",
    "plt.axvline(final_model.best_ntree_limit, color='grey', label='Optimal number of trees')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jobb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
